# 09 â€“ LangChain Basics: Chaining Logic with LLMs

This optional section introduces LangChain â€“ a framework that helps you build modular, chainable pipelines around LLMs.

> LangChain is ideal for building tool-aware agents, memory handling, and multi-step logic.

---

## ğŸ¯ Goals

- Understand LangChain's capabilities and use cases
- Create a simple LLMChain with prompt templates
- Integrate a custom tool (e.g., log lookup)
- Build an agent capable of dynamic tool usage

---

## ğŸ“‚ Folder Structure

```bash
09-langchain-basic/
â”œâ”€â”€ agent_chain.py          # Full agent using the tool via LangChain
â”œâ”€â”€ .env.example            # OpenAI key
â””â”€â”€  README.md
```

---

## ğŸ§  Concepts

### âœ… LangChain Features

- Prompt Templates
- Chains (sequential logic)
- Agents (dynamic tool routing)
- Memory
- Tool/API Integration

---

## ğŸš€ Quickstart

Install dependencies:

```bash
pip install langchain langchain_community openai python-dotenv
```

Run the agent (with tool integration):

```bash
python agent_chain.py
```

---

## ğŸ” Example Prompt Flow

```bash
User: Search logs for 'docker error'
â†’ Agent detects need for tool â†’ Calls `search_logs()` â†’ Responds with simulated output
```

You can modify the chain or agent to:

- Log outputs to memory
- Use multiple tools
- Chain multi-step reasoning

---

## âš ï¸ Disclaimer

LangChain is powerful but should be used wisely â€“ avoid overengineering when simpler solutions suffice ğŸ˜…

---

More info:

ğŸ‘‰ [LangChain Documentation](https://python.langchain.com/)
