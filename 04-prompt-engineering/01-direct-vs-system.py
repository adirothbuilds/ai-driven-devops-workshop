# 04-prompt-engineering

import os
from openai import OpenAI
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Initialize OpenAI client with API key
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def call_direct_prompt(question: str) -> str:
    """
    Sends a direct prompt to the GPT-3.5-turbo model and retrieves the response.
    
    Args:
        question (str): The input question or prompt to be sent to the model.
    
    Returns:
        str: The response content generated by the model.
    """
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": question}],
        temperature=0.4
    )
    return response.choices[0].message.content.strip()

def call_system_prompt(question: str) -> str:
    """
    Sends a question to a chat-based AI model using a system prompt and returns the response.
    
    Args:
        question (str): The user's question to be sent to the AI model.
    
    Returns:
        str: The AI model's response to the question, formatted as a concise string.
    """
    system_message = "You are a helpful and precise DevOps assistant. Answer clearly and concisely."
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_message},
            {"role": "user", "content": question}
        ],
        temperature=0.4
    )
    return response.choices[0].message.content.strip()

if __name__ == "__main__":
    print("""
ðŸ’¬ Question: How can I reduce the size of my Docker image?
""")

    direct_answer = call_direct_prompt("How can I reduce the size of my Docker image?")
    print("""ðŸŸ  Direct Prompt Output:
""", direct_answer)

    print("""
------------------------------
""")

    system_answer = call_system_prompt("How can I reduce the size of my Docker image?")
    print("""ðŸ”µ System Prompt Output:
""", system_answer)