---
marp: true
paginate: true
---

# 06 – CI Integration

In this module, we demonstrate how to connect an LLM into a CI process to enhance post-build visibility.

Whether your pipeline succeeds or fails, a short, clear summary generated by AI can:

- Help developers understand issues faster
- Reduce alert fatigue
- Add human-like feedback to raw logs or statuses

---

## 🎯 Objective

Integrate LLM analysis into CI/CD pipelines (Jenkins or GitHub Actions) to:

- Summarize build logs
- Classify failure types
- Email or post summaries for visibility

---

## 📁 File Structure

```bash
06-ci-integration/
├── summarize_ci_log.py        # Script to be called from CI job
├── example_github_action.yml  # Demo GitHub Actions integration
├── ci_log_example.txt         # Sample CI output log
├── .env.example               # API key + optional email creds
└── README.md
```

---

## 🔧 Requirements

- Python 3.9+
- `openai>=1.0.0`
- `python-dotenv`

Install:

```bash
pip install openai python-dotenv
```

---

## 🚀 Basic Usage

```bash
python summarize_ci_log.py ci_log_example.txt
```

You’ll get a plain-text summary in stdout (or via email if configured).

---

## ⚙️ GitHub Actions Integration

See `example_github_action.yml`:

- Runs your tests
- On failure, runs the LLM summarizer
- Posts the result as a job annotation or sends an email

---

## 💡 Use Cases

- Summarize `pytest` or `npm test` output
- Classify common build failures
- Attach summaries to alerts or issue tickets

---

## ⚠️ Notes

- Use sparingly to control cost (you can summarize only on failure)
- In real CI systems, sanitize sensitive logs before uploading to LLM
- Summaries are **augmentations**, not replacements for full logs

---

This is where Dev meets AI – right in your pipeline 🛠️🤖
